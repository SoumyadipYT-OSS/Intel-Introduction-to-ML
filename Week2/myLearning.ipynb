{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Supervised Learning\n",
    "\n",
    "#### >> Learning Objectives\n",
    "• Explain supervised learning and how it can be applied to \n",
    "regression and classification problems.\n",
    "\n",
    "• Apply K-Nearest Neighbor (KNN) algorithm for \n",
    "classification.\n",
    "\n",
    "• Apply Intel® Extension for Scikit-learn* to leverage \n",
    "underlying compute capabilities of hardware\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling: The Syntax\n",
    "##### **Import the class containing the scaling method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Create an instance of the class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "StdSc = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = {\n",
    "    'Feature1': [10, 20, 30, 40, 50],\n",
    "    'Feature2': [100, 200, 300, 400, 500],\n",
    "    'Feature3': [1000, 2000, 3000, 4000, 5000]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Create a DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Feature1  Feature2  Feature3\n",
      "0        10       100      1000\n",
      "1        20       200      2000\n",
      "2        30       300      3000\n",
      "3        40       400      4000\n",
      "4        50       500      5000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X_data = pd.DataFrame(data)\n",
    "print(\"Original Data:\")\n",
    "print(X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Fit the scaling parameters and then transform the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StdSc\n",
      "StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "StdSc = StdSc.fit(X_data)\n",
    "print(\"StdSc\")\n",
    "print(StdSc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.41421356 -1.41421356 -1.41421356]\n",
      " [-0.70710678 -0.70710678 -0.70710678]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.70710678  0.70710678  0.70710678]\n",
      " [ 1.41421356  1.41421356  1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = StdSc.transform(X_data)\n",
    "print(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Convert the scaled data back to a DataFrame for better readability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaled Data:\n",
      "   Feature1  Feature2  Feature3\n",
      "0 -1.414214 -1.414214 -1.414214\n",
      "1 -0.707107 -0.707107 -0.707107\n",
      "2  0.000000  0.000000  0.000000\n",
      "3  0.707107  0.707107  0.707107\n",
      "4  1.414214  1.414214  1.414214\n"
     ]
    }
   ],
   "source": [
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X_data.columns)\n",
    "print(\"\\nScaled Data:\")\n",
    "print(X_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **MinMaxScaler**\n",
    "The `MinMaxScaler` scales the data to a specified range, typically between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MinMax Scaled Data:\n",
      "   Feature1  Feature2  Feature3\n",
      "0      0.00      0.00      0.00\n",
      "1      0.25      0.25      0.25\n",
      "2      0.50      0.50      0.50\n",
      "3      0.75      0.75      0.75\n",
      "4      1.00      1.00      1.00\n"
     ]
    }
   ],
   "source": [
    "minmax_scaler = MinMaxScaler()\n",
    "X_minmax_scaled = minmax_scaler.fit_transform(X_data)\n",
    "X_minmax_scaled_df = pd.DataFrame(X_minmax_scaled, columns=X_data.columns)\n",
    "print(\"\\nMinMax Scaled Data:\")\n",
    "print(X_minmax_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **MaxAbsScaler**\n",
    "The `MaxAbsScaler` scales each feature by its maximum absolute value, preserving the sign of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MaxAbs Scaled Data:\n",
      "   Feature1  Feature2  Feature3\n",
      "0       0.2       0.2       0.2\n",
      "1       0.4       0.4       0.4\n",
      "2       0.6       0.6       0.6\n",
      "3       0.8       0.8       0.8\n",
      "4       1.0       1.0       1.0\n"
     ]
    }
   ],
   "source": [
    "maxabs_scaler = MaxAbsScaler()\n",
    "X_maxabs_scaled = maxabs_scaler.fit_transform(X_data)\n",
    "X_maxabs_scaled_df = pd.DataFrame(X_maxabs_scaled, columns=X_data.columns)\n",
    "print(\"\\nMaxAbs Scaled Data:\")\n",
    "print(X_maxabs_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n",
      "Prediction for [[4 5]]: [1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Sample data: features and labels\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [5, 6], [6, 7], [7, 8]])\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Create the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Example prediction\n",
    "new_data = np.array([[4, 5]])\n",
    "prediction = knn.predict(new_data)\n",
    "print(f\"Prediction for {new_data}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
